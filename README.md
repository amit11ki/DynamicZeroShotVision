# Zero-Shot Object Detection with OWL-ViT

This project demonstrates real-time **zero-shot object detection** using the [OWL-ViT](https://huggingface.co/google/owlvit-base-patch32) model from Hugging Face Transformers. The system can detect **objects described by arbitrary text prompts** without retraining.

---

## ğŸ§  Overview

**DynamicZeroShotVision** is designed to:

- Accept input from a webcam or a local video file.
- Use custom object categories (e.g., lightbulb, matchstick, monitor, lion, gaming console) that are not part of the COCO dataset.
- Process each video frame using a zero-shot model to detect objects.
- Display annotated video with bounding boxes, labels, and confidence scores.
- Allow live updating of detection classes during runtime.
- Log predictions for further analysis.
---


## ğŸ–¥ï¸ Example Classes

The system is initialized with some example classes:

```text
lightbulb, matchstick, monitor, lion, gaming console
```

You can change these live by pressing `c` during detection.

---

## ğŸ“¦ Installation

1. **Clone the repository**
```bash
git clone https://github.com/amit11ki/DynamicZeroShotVision.git
cd DynamicZeroShotVision
```

2. **Install dependencies**
```bash
pip install torch opencv-python transformers numpy pillow
```

---

## â–¶ï¸ Usage

### Command Line Arguments
```bash
python main.py --source 0                      # Use webcam (default)
python main.py --source path/to/video.mp4      # Use video file
python main.py --no-jit                        # Disable TorchScript acceleration
```

## âŒ¨ï¸ Keyboard Controls
While the application is running:

- `q`: Quit the program
- `c`: Change detection classes dynamically

---

## ğŸ“ Logs

Detection results are saved to:
```
detections_log.json
```

Each entry includes the frame number, timestamp, and detected objects.

---

## ğŸ“ File Structure

```text
â”œâ”€â”€ main.py              # Main detection script
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ detections_log.json  # Output logs
â””â”€â”€ README.md            # Project documentation
```

---

## ğŸ§  Model Info

- Model: `google/owlvit-base-patch32`
- Source: [Hugging Face](https://huggingface.co/google/owlvit-base-patch32)
- Framework: PyTorch + Transformers

---

## ğŸ’¡ Notes

- Performance may vary based on GPU/CPU.
- Resize dimensions for detection: **320x320**.
- Supports only custom classes.

---

## ğŸ“œ License

This project is for educational/research purposes. Respect model and dataset licenses.



## ğŸ”® Future Improvements

- **Live Prompt Editing:** Change detection classes without pausing the stream.
- **Performance Optimizations:** Speed up frame processing and inference.
- **Dashboard UI:** Visualize detections and stats via a browser-based dashboard.
- **Model Acceleration:** Explore ONNX or advanced TorchScript improvements.

